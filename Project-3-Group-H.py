# -*- coding: utf-8 -*-
"""Copy of Copy of Project3_GroupH_2_27.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/ajadams123/ATMS-597-SP-2020-Project-3-Group-H/blob/master/Project3_GroupH_2_28.ipynb

Copyrights: Group H (Dongwei Fu, Alex Adams, and Xinchang Li.)

### module import
"""

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
import cartopy.crs as ccrs  # coordinate reference system
import matplotlib.ticker as mticker
import cartopy.feature as cfeature
import cartopy
from google.colab import drive
import wget
import re
import matplotlib.pyplot as plt
import requests
from bs4 import BeautifulSoup
import numpy as np
from datetime import datetime
import pandas as pd
import xarray as xr
!pip install netcdf4
!pip install pydap
!pip install wget
# install and load necessary modules.

"""### Download GPCP data"""

"""
GPCP Daily Data:
Robert; Wang, Jian-Jian; Sapiano, Mathew; Huffman, George;
 Bolvin, David; Nelkin, Eric; and NOAA CDR Program (2017).
  Global Precipitation Climatology Project (GPCP) Climate
   Data Record (CDR), Version 1.3 (Daily).
NOAA National Centers for Environmental Information.
doi:10.7289/V5RX998Z
02/27/2020

"""

# mount google drive to use storage
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/Project_3_gpcp/

years = np.arange(1996, 2020)  # for the years 1996 to 2019
url_home = 'https://www.ncei.noaa.gov/data/global-precipitation'\
           '-climatology-project-gpcp-daily/access/'

gpcp_file_name = []  # a list to store the gpcp filenames
datasets = []  # datasets list to store all the precip. data
for year in years:
    gpcp_url = url_home + str(year) + '/'
    response = requests.get(gpcp_url)

    soup = BeautifulSoup(response.text, 'html.parser')
    # from metadata only download .nc files
    gpcp_file_list = soup.find_all('a', href=re.compile(r"\.nc$"))
    print(year)  # to indicate which year it is currently downloading
    for s in gpcp_file_list:
        filename = s.contents[0]
        file_url = (gpcp_url + filename)
        # print(file_url)
        wget.download(file_url)
        nc = xr.open_dataset(filename)
        # load these datafields into precip variable
        precip = xr.DataArray(
            nc['precip'], dims=[
                'time', 'latitude', 'longitude'])
        # add the precip variable to the datasets list.
        datasets.append(precip)
        !rm "{filename}"  # delete gpcp_file
# combine the datasets to an xarray object in terms of "time"
combined = xr.concat(datasets, dim='time')

# make the xarray object a dataset.
combined_dataset = combined.to_dataset(name='precip')

# remove all duplicated "time"
mdata = combined_dataset.sel(
    time=~combined_dataset.indexes['time'].duplicated())

# save the xarray dataset to a single netcdf file
mdata.to_netcdf('combined_1996_2019_precip.nc')

"""### Getting the 95 percentile of daily precipitation for
        Melbourne, Australia."""

mdata = xr.open_dataset('combined_1996_2019_precip.nc')  # read in the dataset
# select the 'DJF' months
mdata_season = mdata.sel(time=(mdata['time.season'] == 'DJF'))

# get the nearest gridpoint value for Melbourne, Aus.
mdata_melbourne = mdata_season.sel(
    longitude=144.9631 - 1,
    latitude=-37.8136,
    method='nearest')

# remove all filled values and bad data.
melbourne_precip = mdata_melbourne.where(mdata_melbourne > -999.0, drop=True)

melbourne_results = melbourne_precip.precip.values  # convert to np.ndarray

# calculate the 95 percentile for precipitation values in Melbourne
np.percentile(melbourne_results, 95)

n = np.arange(1, len(melbourne_results) + 1) / np.float(len(melbourne_results))
Xs = np.sort(melbourne_results)
# plotting the CDF for Melbourne 'DJF' precipitation.
fig, ax = plt.subplots(figsize=(12, 8))
ax.step(Xs, n)
plt.axhline(0.95, c='b', ls='--', label='y=0.95')
plt.axvline(
    np.percentile(
        melbourne_results,
        95),
    c='r',
    ls='--',
    label='$95^{th}$ Percentile')
plt.xlabel('GPCP Daily Precip. (mm)')
plt.ylabel('Cumulative Probability')
plt.title('Cumulative Probability Distribution Function for DJF'
          'daily precip. in Melbourne, Australia from 1996-2019')
plt.legend()
plt.show()

# filter to only include extreme precipitation days
melbourne_95 = mdata_melbourne.where(
    mdata_melbourne.precip >= np.percentile(
        melbourne_results, 95), drop=True)

# output the extreme precipitation days to .nc files
melbourne_95.to_netcdf(
    'melbourne_95.nc', encoding={
        'precip': {
            '_FillValue': -9999.0}})

"""### Global long term mean data"""

ltm_baseurl = 'https://www.esrl.noaa.gov/psd/thredds/'\
              'dodsC/Datasets/ncep.reanalysis.derived'
ltm_item = {
    # True indicates that a level should be selected
    'uwnd_250': [('/pressure/uwnd.mon.1981-2010.'
                  'ltm.nc'), True, 250, 'uwnd'],
    'vwnd_250': [('/pressure/vwnd.mon.1981-2010.'
                  'ltm.nc'), True, 250, 'vwnd'],
    'skt': [('/surface_gauss/skt.sfc.mon.1981-2010.'
             'ltm.nc'), False, 0, 'skt'],
    'uwnd_sfc': [('/surface/uwnd.sig995.mon.1981-2010'
                  '.ltm.nc'), False, 0, 'uwnd'],
    'vwnd_sfc': [('/surface/vwnd.sig995.mon.1981-2010.'
                  'ltm.nc'), False, 0, 'vwnd'],
    'pr_wtr': [('/surface/pr_wtr.eatm.mon.1981-2010.'
                'ltm.nc'), False, 0, 'pr_wtr'],
    'wspd_250': [('/pressure/wspd.mon.1981-2010.'
                  'ltm.nc'), True, 250, 'wspd'],
}

ltm_data = {}
for key in ltm_item.keys():
    if not ltm_item[key][1]:
        d = xr.open_dataset(ltm_baseurl +
                            ltm_item[key][0], engine='netcdf4')
    elif ltm_item[key][1]:
        d = xr.open_dataset(
            ltm_baseurl +
            ltm_item[key][0],
            engine='netcdf4').sel(
            level=ltm_item[key][2])
    data = d.sel(time=d.time.dt.season == 'DJF')
    data_mean = data[ltm_item[key][3]].mean(dim='time')
    ltm_data.update({key: data_mean})

ltm_data

# note that skt ltm data are in degC while daily data are in degK;
# for the ease of the anomaly calculation we will update the numbers in 'skt'
# DataArray so they also have degK as units:
skt_mean_K = ltm_data['skt'] + 273.15
ltm_data.update(skt=skt_mean_K)
ltm_data

"""### extreme precip days data"""

!ls

dates = xr.open_dataset('melbourne_95_update.nc', engine='netcdf4')
dates['time']

# since the first xprecip date is in 1997, so we start from 1997
years = pd.date_range(
    start='1997-01-01',
    end='2019-12-01',
    freq='AS')  # 30 years

xprecip_baseurl = 'https://www.esrl.noaa.gov/psd/thredds/'\
                  'dodsC/Datasets/ncep.reanalysis.dailyavgs'
# a dictionary of:
# 'varname' = [url, whether it has levels,
#  what level to use, varname in DataSet]
xprecip_item = {
    'uwnd_250': ['/pressure/uwnd.', True, 250, 'uwnd'],
    'vwnd_250': ['/pressure/vwnd.', True, 250, 'vwnd'],
    'skt': ['/surface_gauss/skt.sfc.gauss.', False, 0, 'skt'],
    'uwnd_sfc': ['/surface/uwnd.sig995.', False, 0, 'uwnd'],
    'vwnd_sfc': ['/surface/vwnd.sig995.', False, 0, 'vwnd'],
    'pr_wtr': ['/surface/pr_wtr.eatm.', False, 0, 'pr_wtr']
    # 'wspd_250' is calculated later
}

xprecip_data = {}
for key in xprecip_item.keys():
    datasets = []
    lv = int(xprecip_item[key][2])
    for iyr in years.year:
        url = xprecip_baseurl + xprecip_item[key][0] + str(iyr) + '.nc'
        dates_iyr = dates.sel(time=dates['time'].dt.year == iyr)['time']
        d = xr.open_dataset(url, engine='netcdf4').sel(time=dates_iyr)
        if xprecip_item[key][1]:
            d = d.sel(level=lv)
        datasets.append(d)
    data = xr.concat(datasets, dim='time')
    data_mean = data[xprecip_item[key][3]].mean(dim='time')
    xprecip_data.update({key: data_mean})

xprecip_data

# adding wspd_250 to xprecip dict
uwnd_mean = xprecip_data['uwnd_250']
vwnd_mean = xprecip_data['vwnd_250']
wdsp_mean = np.sqrt(uwnd_mean**2 + vwnd_mean**2)

# give it a name to match ltm dataset
wdsp_mean.name = 'wspd'

xprecip_data.update({'wspd_250': wdsp_mean})

ltm_data['wspd_250'], xprecip_data['wspd_250']

"""### calculate anomalies"""

keys = ltm_data.keys()

anom_data = {}
for key in keys:
    anom = xprecip_data[key] - ltm_data[key]
    anom_data.update({key: anom})

anom_data

"""## plotting with Cartopy

### install Cartopy and import modules
"""

# install cartopy
!apt - get - qq install libproj - dev proj - data proj - bin libgeos - dev
!pip install Cython
!pip install - -upgrade - -force - reinstall shapely - -no - binary shapely
!pip install cartopy

# import modules

"""### global mean maps and vector plots for extreme precip days"""

# create figure, axes instances.
fig = plt.figure(figsize=(20, 30))

mkeys = [
    'skt',
    'pr_wtr',
    'wspd_250',
    'Temperature (C)',
    'Precipitable Water (kg/m^2)',
    'Wind Speed (m/s)',
    'Skin Temperature',
    'Precipitable Water',
    '250 hPa Wind Speed']
n = int(len(mkeys) / 3)

for i in range(n):
    ax = plt.subplot(
        n,
        1,
        i + 1,
        projection=ccrs.PlateCarree(
            central_longitude=180))
    data = xprecip_data[mkeys[i]]
    plt.contourf(
        data['lon'],
        data['lat'],
        data,
        transform=ccrs.PlateCarree(),
        levels=20)
    ax.set_global()  # for global dataset
    ax.coastlines()
    plt.colorbar().set_label(mkeys[i + 3])
    plt.title(mkeys[i + 6] + ' Global Means')
    plt.plot(144 - 180, -38, marker='*', markersize=15, color='red')

plt.show()
fig.savefig('sktprwspglobmeans.png')

fig = plt.figure(figsize=(20, 20))

plot_dict = xprecip_data
skip = 2

# 250hPa wind vectors
ax1 = plt.subplot(2, 1, 1, projection=ccrs.PlateCarree())
ax1.stock_img()
ax1.set_global()
ax1.set_title('250 hPa Wind Vectors Global Means')
ax1.quiver(plot_dict['uwnd_250']['lon'][::skip],
           plot_dict['uwnd_250']['lat'][::skip],
           plot_dict['uwnd_250'][::skip,
                                 ::skip],
           plot_dict['vwnd_250'][::skip,
                                 ::skip])  # , transform=vector_crs)
ax1.plot(144, -38, marker='*', markersize=15, color='red')


# surface wind vectors
ax2 = plt.subplot(2, 1, 2, projection=ccrs.PlateCarree())
ax2.set_global()
ax2.stock_img()
ax2.set_title('Surface Wind Vectors Global Means')
ax2.quiver(plot_dict['uwnd_sfc']['lon'][::skip],
           plot_dict['uwnd_sfc']['lat'][::skip],
           plot_dict['uwnd_sfc'][::skip,
                                 ::skip],
           plot_dict['vwnd_sfc'][::skip,
                                 ::skip])  # , transform=vector_crs)
ax2.plot(144, -38, marker='*', markersize=15, color='red')

plt.show()
fig.savefig('250surfwindvglobmeans.png')

"""### long term mean maps and vector plots"""

# create figure, axes instances.
fig = plt.figure(figsize=(20, 30))

mkeys = [
    'skt',
    'pr_wtr',
    'wspd_250',
    'Temperature (C)',
    'Precipitable Water (kg/m^2)',
    'Wind Speed (m/s)',
    'Skin Temperature',
    'Precipitable Water',
    '250 hPa Wind Speed']
n = int(len(mkeys) / 3)

for i in range(n):
    ax = plt.subplot(
        n,
        1,
        i + 1,
        projection=ccrs.PlateCarree(
            central_longitude=180))
# plotting dict
    data = ltm_data[mkeys[i]]
    plt.contourf(
        data['lon'],
        data['lat'],
        data,
        transform=ccrs.PlateCarree(),
        levels=20,
        cmap='viridis')
    ax.set_global()  # for global dataset
    ax.coastlines()
    plt.colorbar().set_label(mkeys[i + 3])
    plt.plot(144 - 180, -38, marker='*', markersize=15, color='red')
    plt.title(mkeys[i + 6] + ' Seasonal Means 1981-2010 DJF')

plt.show()
fig.savefig('sktprwspdjfmeans.png')

fig = plt.figure(figsize=(20, 20))
# wnd250 = anom_data['uwnd_250']

plot_dict = ltm_data
skip = 2

# 250hPa wind vectors
ax1 = plt.subplot(2, 1, 1, projection=ccrs.PlateCarree())
ax1.add_feature(cartopy.feature.OCEAN, zorder=0)
ax1.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')
ax1.set_global()
ax1.stock_img
# ax1.gridlines()
ax1.set_title('250 hPa Wind Vectors Seasonal Means 1981-2010 DJF')
ax1.quiver(plot_dict['uwnd_250']['lon'][::skip],
           plot_dict['uwnd_250']['lat'][::skip],
           plot_dict['uwnd_250'][::skip,
                                 ::skip],
           plot_dict['vwnd_250'][::skip,
                                 ::skip])
ax1.plot(144, -38, marker='*', markersize=15, color='red')


# surface wind vectors
ax2 = plt.subplot(2, 1, 2, projection=ccrs.PlateCarree())
ax2.add_feature(cartopy.feature.OCEAN, zorder=0)
ax2.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')
ax2.set_global()
ax2.stock_img()
# ax2.gridlines()
ax2.set_title('Surface hPa Wind Vectors Seasonal Means 1981-2010 DJF')
ax2.quiver(plot_dict['uwnd_sfc']['lon'][::skip],
           plot_dict['uwnd_sfc']['lat'][::skip],
           plot_dict['uwnd_sfc'][::skip,
                                 ::skip],
           plot_dict['vwnd_sfc'][::skip,
                                 ::skip])
ax2.plot(144, -38, marker='*', markersize=15, color='red')

plt.show()
fig.savefig('250surfwindvdjfmeans.png')

"""### Anomalies maps and vector plots"""

# create figure, axes instances.
fig = plt.figure(figsize=(20, 30))

mkeys = [
    'skt',
    'pr_wtr',
    'wspd_250',
    'Temperature (C)',
    'Precipitable Water (kg/m^2)',
    'Wind Speed (m/s)',
    'Skin Temperature',
    'Precipitable Water',
    '250 hPa Wind Speed']
n = int(len(mkeys) / 3)

for i in range(n):
    ax = plt.subplot(
        n,
        1,
        i + 1,
        projection=ccrs.PlateCarree(
            central_longitude=180))
    data = anom_data[mkeys[i]]
    plt.contourf(
        data['lon'],
        data['lat'],
        data,
        transform=ccrs.PlateCarree(),
        cmap='seismic',
        levels=20)
    ax.set_global()  # for global dataset
    ax.coastlines()
    plt.colorbar().set_label(mkeys[i + 3])
    plt.title(mkeys[i + 6] + 'Anomalies')
    plt.plot(144 - 180, -38, marker='*', markersize=15, color='black')

plt.show()
fig.savefig('sktprwspanom.png')

fig = plt.figure(figsize=(20, 20))
# wnd250 = anom_data['uwnd_250']

plot_dict = anom_data
skip = 2

# 250hPa wind vectors
ax1 = plt.subplot(2, 1, 1, projection=ccrs.PlateCarree())
ax1.set_global()
ax1.stock_img()
ax1.plot(144, -38, marker='*', markersize=15, color='red')
ax1.set_title('250 hPa Wind Vector Anomalies')

ax1.quiver(plot_dict['uwnd_250']['lon'][::skip],
           plot_dict['uwnd_250']['lat'][::skip],
           plot_dict['uwnd_250'][::skip,
                                 ::skip],
           plot_dict['vwnd_250'][::skip,
                                 ::skip])


# surface wind vectors
ax2 = plt.subplot(2, 1, 2, projection=ccrs.PlateCarree())
ax2.stock_img()
ax2.set_global()
ax2.plot(144, -38, marker='*', markersize=15, color='red')
ax2.set_title('Surface Wind Vector Anomalies')
ax2.quiver(plot_dict['uwnd_sfc']['lon'][::skip],
           plot_dict['uwnd_sfc']['lat'][::skip],
           plot_dict['uwnd_sfc'][::skip,
                                 ::skip],
           plot_dict['vwnd_sfc'][::skip,
                                 ::skip])


plt.show()

fig.savefig('250surfwndanom.png')

"""## Creating data and plots for 500 hPa and 850 hPa variables"""

# downloading long term monthly means for anomaly calculation
hght500mean1981_2010 = xr.open_dataset(
    ('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.'
        'reanalysis.derived/pressure/hgt.mon.1981-2010.ltm.nc'),
    engine='netcdf4').sel(
        level=500)
uwind500mean1981_2010 = xr.open_dataset(
    ('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.'
        'reanalysis.derived/pressure/uwnd.mon.1981-2010.ltm.nc'),
    engine='netcdf4').sel(
        level=500)
vwind500mean1981_2010 = xr.open_dataset(
    ('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.'
        'reanalysis.derived/pressure/vwnd.mon.1981-2010.ltm.nc'),
    engine='netcdf4').sel(
        level=500)
uwind850mean1981_2010 = xr.open_dataset(
    ('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.'
        'reanalysis.derived/pressure/uwnd.mon.1981-2010.ltm.nc'),
    engine='netcdf4').sel(
        level=850)
vwind850mean1981_2010 = xr.open_dataset(
    ('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.'
        'reanalysis.derived/pressure/vwnd.mon.1981-2010.ltm.nc'),
    engine='netcdf4').sel(
        level=850)
temp850mean1981_2010 = xr.open_dataset(
    ('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.'
        'reanalysis.derived/pressure/air.mon.1981-2010.ltm.nc'),
    engine='netcdf4').sel(
        level=850)
sphum850mean1981_2010 = xr.open_dataset(
    ('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.'
        'reanalysis.derived/pressure/shum.mon.1981-2010.ltm.nc'),
    engine='netcdf4').sel(
        level=850)

# selecting only December, January, February months
hght500djf = hght500mean1981_2010.sel(
    time=hght500mean1981_2010.time.dt.season == 'DJF')
uwind500djf = uwind500mean1981_2010.sel(
    time=uwind500mean1981_2010.time.dt.season == 'DJF')
vwind500djf = vwind500mean1981_2010.sel(
    time=vwind500mean1981_2010.time.dt.season == 'DJF')
uwind850djf = uwind850mean1981_2010.sel(
    time=uwind850mean1981_2010.time.dt.season == 'DJF')
vwind850djf = vwind850mean1981_2010.sel(
    time=vwind850mean1981_2010.time.dt.season == 'DJF')
temp850djf = temp850mean1981_2010.sel(
    time=temp850mean1981_2010.time.dt.season == 'DJF')
sphum850djf = sphum850mean1981_2010.sel(
    time=sphum850mean1981_2010.time.dt.season == 'DJF')

# calculating seasonal mean for each field
hght500djfmean = hght500djf.mean(dim='time')
uwind500djfmean = uwind500djf.mean(dim='time')
vwind500djfmean = vwind500djf.mean(dim='time')
uwind850djfmean = uwind850djf.mean(dim='time')
vwind850djfmean = vwind850djf.mean(dim='time')
temp850djfmean = temp850djf.mean(dim='time')
sphum850djfmean = sphum850djf.mean(dim='time')

means = [
    hght500djfmean,
    uwind500djfmean,
    vwind500djfmean,
    uwind850djfmean,
    vwind850djfmean,
    temp850djfmean,
    sphum850djfmean]

# Plotting seasonal mean winds
elev = ['500', '700', '850']

ind = [0, 2]
for i in range(0, 2):
    fig = plt.figure(figsize=(20, 10))

    ax = plt.axes(projection=ccrs.PlateCarree())

    skip = 2
    ax.quiver(means[ind[i] + 1]['lon'][::skip],
              means[ind[i] + 1]['lat'][::skip],
              means[ind[i] + 1]['uwnd'][::skip, ::skip],
              means[ind[i] + 2]['vwnd'][::skip, ::skip],
              transform=ccrs.PlateCarree())
    ax.coastlines()
    ax.plot(144, -38, marker='*', markersize=15, color='r')
    plt.title(elev[ind[i]] + ' hPa Wind Vectors Seasonal Mean 1981-2010 DJF')
    plt.tight_layout()
    ax.stock_img()
    plt.show()
    fig.savefig('winds' + elev[ind[i]] + 'djfmean.png')

# Plotting seasonal mean Geopotential Heights
fig = plt.figure(figsize=(20, 10))

ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))

plt.contour(means[0]['lon'], means[0]['lat'], means[0]['hgt'],
            transform=ccrs.PlateCarree(), cmap='viridis', levels=20)
ax.coastlines()
plt.plot(144 - 180, -38, marker='*', markersize=15, color='r')
plt.title('500 hPa Geopotential Heights Seasonal Mean 1981-2010 DJF')
plt.colorbar().set_label('Height (m)')
plt.tight_layout()
plt.show()
fig.savefig('hght500djfmean.png')

# Plotting seasonal mean Temps and Specific Humidity
names = [
    'air',
    'shum',
    'Temperature',
    'Specific Humidity',
    'Temperature (C)',
    'Humidity (g/kg)']
for i in range(0, 2):
    fig = plt.figure(figsize=(20, 10))

    ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))

    plt.contourf(means[i + 5]['lon'],
                 means[i + 5]['lat'],
                 means[i + 5][names[i]],
                 transform=ccrs.PlateCarree(),
                 cmap='viridis',
                 levels=20)
    ax.coastlines()
    plt.plot(144 - 180, -38, marker='*', markersize=15, color='r')
    plt.title('850 hPa ' + names[i + 2] + ' Seasonal Mean 1981-2010 DJF')
    plt.colorbar().set_label(names[i + 4])
    plt.tight_layout()
    plt.show()
    fig.savefig(names[i] + '850djfmean.png')

# loading in extreme precip dates
datefile = xr.open_dataset('/content/melbourne_95_update.nc', engine='netcdf4')
dates = datefile['time']

# downloading daily data from extreme precip days
years = pd.date_range(
    start='1997-01-01',
    end='2019-12-01',
    freq='AS')  # 30 years

# heights
hght500 = []
for year in years.year:
    # print('working on '+str(year))
    hght500ds = xr.open_dataset(
        ('http://www.esrl.noaa.gov/psd/thredds'
            '/dodsC/Datasets/ncep.reanalysis.dailyavgs/pressure/hgt.') +
        str(year) +
        '.nc',
        engine='netcdf4').sel(
        level=500,
        time=dates.sel(
            time=dates['time'].dt.year == year)['time'])
    hght500.append(hght500ds)
hght500_conc = xr.concat(hght500, dim='time')
hght500daily = hght500_conc.mean(dim='time')
print('done with hght')

# 500mb uwind
uwind500 = []
for year in years.year:
    # print('working on '+str(year))
    uwind500ds = xr.open_dataset(
        ('http://www.esrl.noaa.gov/psd/thredds'
            '/dodsC/Datasets/ncep.reanalysis.dailyavgs/pressure/uwnd.') +
        str(year) +
        '.nc',
        engine='netcdf4').sel(
        level=500,
        time=dates.sel(
            time=dates['time'].dt.year == year)['time'])
    uwind500.append(uwind500ds)
uwind500_conc = xr.concat(uwind500, dim='time')
uwind500daily = uwind500_conc.mean(dim='time')
print('done with uwind 500')

# 500mb vwind
vwind500 = []
for year in years.year:
    # print('working on '+str(year))
    vwind500ds = xr.open_dataset(
        ('http://www.esrl.noaa.gov/psd/thredds'
            '/dodsC/Datasets/ncep.reanalysis.dailyavgs/pressure/vwnd.') +
        str(year) +
        '.nc',
        engine='netcdf4').sel(
        level=500,
        time=dates.sel(
            time=dates['time'].dt.year == year)['time'])
    vwind500.append(vwind500ds)
vwind500_conc = xr.concat(vwind500, dim='time')
vwind500daily = vwind500_conc.mean(dim='time')
print('done with vwind 500')

# 850mb uwind
uwind850 = []
for year in years.year:
    # print('working on '+str(year))
    uwind850ds = xr.open_dataset(
        ('http://www.esrl.noaa.gov/psd/thredds'
            '/dodsC/Datasets/ncep.reanalysis.dailyavgs/pressure/uwnd.') +
        str(year) +
        '.nc',
        engine='netcdf4').sel(
        level=850,
        time=dates.sel(
            time=dates['time'].dt.year == year)['time'])
    uwind850.append(uwind850ds)
uwind850_conc = xr.concat(uwind850, dim='time')
uwind850daily = uwind850_conc.mean(dim='time')
print('done with uwind 850')

# 850mb vwind
vwind850 = []
for year in years.year:
    # ('working on '+str(year))
    vwind850ds = xr.open_dataset(
        ('http://www.esrl.noaa.gov/psd/thredds/'
            'dodsC/Datasets/ncep.reanalysis.dailyavgs/pressure/vwnd.') +
        str(year) +
        '.nc',
        engine='netcdf4').sel(
        level=850,
        time=dates.sel(
            time=dates['time'].dt.year == year)['time'])
    vwind850.append(vwind850ds)
vwind850_conc = xr.concat(vwind850, dim='time')
vwind850daily = vwind850_conc.mean(dim='time')
print('done with vwind 850')

# 850mb temp
temp850 = []
for year in years.year:
    # print('working on '+str(year))
    temp850ds = xr.open_dataset(
        ('http://www.esrl.noaa.gov/psd/thredds/'
            'dodsC/Datasets/ncep.reanalysis.dailyavgs/pressure/air.') +
        str(year) +
        '.nc',
        engine='netcdf4').sel(
        level=850,
        time=dates.sel(
            time=dates['time'].dt.year == year)['time'])
    temp850.append(temp850ds)
temp850_conc = xr.concat(temp850, dim='time')
temp850daily = temp850_conc.mean(dim='time')
print('done with temp 850')

# 850mb sphum
sphum850 = []
for year in years.year:
    # print('working on '+str(year))
    sphum850ds = xr.open_dataset(
        ('http://www.esrl.noaa.gov/psd/thredds/'
            'dodsC/Datasets/ncep.reanalysis.dailyavgs/pressure/shum.') +
        str(year) +
        '.nc',
        engine='netcdf4').sel(
        level=850,
        time=dates.sel(
            time=dates['time'].dt.year == year)['time'])
    sphum850.append(sphum850ds)
sphum850_conc = xr.concat(sphum850, dim='time')
sphum850daily = sphum850_conc.mean(dim='time')

print('done with sphum 850')

# correcting for unit differences
temp850dailycorr = temp850daily['air'] - 273.15
sphum850dailycorr = sphum850daily['shum'] * 1000.

dailyavgs = [
    hght500daily,
    uwind500daily,
    vwind500daily,
    uwind850daily,
    vwind850daily,
    temp850dailycorr,
    sphum850dailycorr]

anoms = []

for i in range(0, 7):
    anoms.append(dailyavgs[i] - means[i])

# plotting global mean fields for 95%+ precip days

# plotting 500 hPa geopotential heights
fig = plt.figure(figsize=(20, 10))
ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))
plt.contour(dailyavgs[0]['lon'], dailyavgs[0]['lat'], dailyavgs[0]['hgt'],
            transform=ccrs.PlateCarree(), cmap='viridis', levels=20)
ax.coastlines()
plt.plot(144 - 180, -38, marker='*', markersize=15, color='r')
plt.title('500 hPa Geopotential Heights Global Means')
plt.colorbar().set_label('Height (m)')
plt.tight_layout()
plt.show()
fig.savefig('hght500globmean.png')

# Plotting winds
elev = ['500', '700', '850']
ind = [0, 2]

for i in range(0, 2):
    fig = plt.figure(figsize=(20, 10))
    ax = plt.axes(projection=ccrs.PlateCarree())
    skip = 2
    plt.quiver(dailyavgs[ind[i] + 1]['lon'][::skip],
               dailyavgs[ind[i] + 1]['lat'][::skip],
               dailyavgs[ind[i] + 1]['uwnd'][::skip, ::skip],
               dailyavgs[ind[i] + 2]['vwnd'][::skip, ::skip],
               transform=ccrs.PlateCarree())
    ax.coastlines()
    plt.plot(144, -38, marker='*', markersize=15, color='r')
    plt.title(elev[ind[i]] + ' hPa Global Mean Wind Vectors')
    plt.tight_layout()
    ax.stock_img()
    plt.show()
    fig.savefig('winds' + elev[ind[i]] + 'globmean.png')

# Plotting Temps and Specific Humidity
names = [
    'air',
    'shum',
    'Temperature',
    'Specific Humidity',
    'Temperature (C)',
    'Humidity (g/kg)']

for i in range(0, 2):
    fig = plt.figure(figsize=(20, 10))
    ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))
    plt.contourf(dailyavgs[i + 5]['lon'],
                 dailyavgs[i + 5]['lat'],
                 dailyavgs[i + 5],
                 transform=ccrs.PlateCarree(),
                 cmap='viridis',
                 levels=20)
    ax.coastlines()
    plt.plot(144 - 180, -38, marker='*', markersize=15, color='r')
    plt.title('850 hPa ' + names[i + 2] + ' Global Means')
    plt.colorbar().set_label(names[i + 4])
    plt.tight_layout()
    plt.show()
    fig.savefig(names[i] + '850globmean.png')

# Plotting anomalies

# plotting height anomalies
fig = plt.figure(figsize=(20, 10))
ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))
plt.contourf(anoms[0]['lon'], anoms[0]['lat'], anoms[0]['hgt'],
             transform=ccrs.PlateCarree(), cmap='seismic', levels=20)
ax.coastlines()
plt.plot(144 - 180, -38, marker='*', markersize=15, color='black')
plt.title('500 hPa Geopotential Height Anomalies')
plt.colorbar().set_label('Height (m)')
plt.tight_layout()
plt.show()
fig.savefig('hght500anom.png')

# plotting wind anomalies
skip = 2

for i in range(0, 2):
    fig = plt.figure(figsize=(20, 10))
    ax = plt.axes(projection=ccrs.PlateCarree())
    plt.quiver(anoms[ind[i] + 1]['lon'][::skip],
               anoms[ind[i] + 1]['lat'][::skip],
               anoms[ind[i] + 1]['uwnd'][::skip, ::skip],
               anoms[ind[i] + 2]['vwnd'][::skip, ::skip],
               transform=ccrs.PlateCarree())
    ax.coastlines()
    plt.plot(144, -38, marker='*', markersize=15, color='r')
    plt.title(elev[ind[i]] + ' hPa Wind Anomalies')
    plt.tight_layout()
    ax.stock_img()
    plt.show()
    fig.savefig('winds' + elev[ind[i]] + 'anom.png')

# Plotting temperature and specific humidity anomalies
names = [
    'air',
    'shum',
    'Temperature',
    'Specific Humidity',
    'Temperature (C)',
    'Humidity (g/kg)']
for i in range(0, 2):
    fig = plt.figure(figsize=(20, 10))

    ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))

    plt.contourf(anoms[i + 5]['lon'],
                 anoms[i + 5]['lat'],
                 anoms[i + 5][names[i]],
                 transform=ccrs.PlateCarree(),
                 cmap='seismic',
                 levels=20)
    ax.coastlines()
    plt.plot(144 - 180, -38, marker='*', markersize=15, color='black')
    plt.title('850 hPa ' + names[i + 2] + ' Anomalies')
    plt.colorbar().set_label(names[i + 4])
    plt.tight_layout()
    plt.show()
    fig.savefig(names[i] + '850anom.png')
